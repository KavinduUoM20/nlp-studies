{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398cd2a4-9a4f-42c0-9490-6322ce706416",
   "metadata": {},
   "source": [
    "## Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50503e3a-2744-4b50-b98d-acdac92ce9cf",
   "metadata": {},
   "source": [
    "Reducing a given word to its base word.\n",
    "\n",
    "1. talking --> talk\n",
    "2. eating  --> eat\n",
    "3. adjustable --> adjust\n",
    "\n",
    "Using fixed rules to obtain base word (removing able,ing) is called <b>Stemming</b>\n",
    "\n",
    "But, in situations where we want to use the knowledge of language (linguistic knowledge) to derive a base word, we called it <b>Lemmatization</b>\n",
    "\n",
    "1. ate --> eat\n",
    "2. hidden --> hide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0fce0b-ca4c-4173-ab31-0f3b6dc62061",
   "metadata": {},
   "source": [
    "Stemming is not supported by <b>Spacy</b>, but BOTH Stemming and Lemmatization are supported by <b>NLTK</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db84b62f-3518-42a3-a731-e00bfc955f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcff706-203f-4128-a774-445f1971685d",
   "metadata": {},
   "source": [
    "#### 1. Stemming using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d2d954-8d6a-4aeb-a96d-8db01be4e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0f526f-bee6-43d3-8398-e00c0e21da0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ----- run\n",
      "Ran ----- ran\n",
      "Running ----- run\n",
      "Runner ----- runner\n",
      "Book ----- book\n",
      "Books ----- book\n",
      "Bookstore ----- bookstor\n",
      "Bookshelf ----- bookshelf\n",
      "Jump ----- jump\n",
      "Jumped ----- jump\n",
      "Jumping ----- jump\n",
      "Jumper ----- jumper\n"
     ]
    }
   ],
   "source": [
    "word_list = ['Run', 'Ran', 'Running', 'Runner', 'Book', 'Books', 'Bookstore', 'Bookshelf', 'Jump', 'Jumped', 'Jumping', 'Jumper']\n",
    "\n",
    "for word in word_list:\n",
    "    print(word, \"-----\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6ea1c-b91a-4d5d-8db2-87f90b8c1134",
   "metadata": {},
   "source": [
    "#### 2. Lemmatization using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62699dc4-e1f8-41c6-8f8e-da9bf2c31cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ----- Run\n",
      "Ran ----- Ran\n",
      "Running ----- Running\n",
      "Runner ----- Runner\n",
      "Book ----- Book\n",
      "Books ----- Books\n",
      "Bookstore ----- Bookstore\n",
      "Bookshelf ----- Bookshelf\n",
      "Jump ----- Jump\n",
      "Jumped ----- Jumped\n",
      "Jumping ----- Jumping\n",
      "Jumper ----- Jumper\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Run Ran Running Runner Book Books Bookstore Bookshelf Jump Jumped Jumping Jumper\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"-----\", word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220dbaf7-e710-4d27-8ccc-fa57761e0afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ----- Run ---ID---> 16173034612666007580\n",
      "Ran ----- Ran ---ID---> 7920933193498127490\n",
      "Running ----- Running ---ID---> 3515731218577779878\n",
      "Runner ----- Runner ---ID---> 8055516351581086986\n",
      "Book ----- Book ---ID---> 2282789789192439378\n",
      "Books ----- Books ---ID---> 14374249698548956695\n",
      "Bookstore ----- Bookstore ---ID---> 4802154648493700311\n",
      "Bookshelf ----- Bookshelf ---ID---> 1977927564827388121\n",
      "Jump ----- Jump ---ID---> 8517166225963065883\n",
      "Jumped ----- Jumped ---ID---> 5367936027753836856\n",
      "Jumping ----- Jumping ---ID---> 13951021020171923904\n",
      "Jumper ----- Jumper ---ID---> 13831740166223223947\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word, \"-----\", word.lemma_,\"---ID--->\",word.lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e39a1-107f-49ad-80f5-70866ed4e205",
   "metadata": {},
   "source": [
    "#### 3. Lemmatization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b08c01f-0c60-4562-8244-9bc7aaad0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57f1ac65-e3d4-4977-96da-6433b9ba6737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Run',\n",
       " 'Ran',\n",
       " 'Running',\n",
       " 'Runner',\n",
       " 'Book',\n",
       " 'Books',\n",
       " 'Bookstore',\n",
       " 'Bookshelf',\n",
       " 'Jump',\n",
       " 'Jumped',\n",
       " 'Jumping',\n",
       " 'Jumper']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"Run Ran Running Runner Book Books Bookstore Bookshelf Jump Jumped Jumping Jumper\"\n",
    "tokens = word_tokenize(doc)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be9bb4e7-284f-4abd-8b44-a9dbfde0149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Run\n",
      "Ran Ran\n",
      "Running Running\n",
      "Runner Runner\n",
      "Book Book\n",
      "Books Books\n",
      "Bookstore Bookstore\n",
      "Bookshelf Bookshelf\n",
      "Jump Jump\n",
      "Jumped Jumped\n",
      "Jumping Jumping\n",
      "Jumper Jumper\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(tokens,lemmatized_tokens):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4d95a-4c4f-4f01-bb18-68096c22dad4",
   "metadata": {},
   "source": [
    "#### 4. Customize Lemmatizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbea49fa-776a-4693-94d1-d3a566132b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('''\"Bro, did you catch the game last night?\" asked Tom, turning to his younger sibling. \"Yeah, bruh, it was intense,\" replied Alex, grinning at his older brother.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6db734ba-b0c4-48f0-b9a1-f92020e70ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" ----- \"\n",
      "Bro ----- bro\n",
      ", ----- ,\n",
      "did ----- do\n",
      "you ----- you\n",
      "catch ----- catch\n",
      "the ----- the\n",
      "game ----- game\n",
      "last ----- last\n",
      "night ----- night\n",
      "? ----- ?\n",
      "\" ----- \"\n",
      "asked ----- ask\n",
      "Tom ----- Tom\n",
      ", ----- ,\n",
      "turning ----- turn\n",
      "to ----- to\n",
      "his ----- his\n",
      "younger ----- young\n",
      "sibling ----- sibling\n",
      ". ----- .\n",
      "\" ----- \"\n",
      "Yeah ----- yeah\n",
      ", ----- ,\n",
      "bruh ----- bruh\n",
      ", ----- ,\n",
      "it ----- it\n",
      "was ----- be\n",
      "intense ----- intense\n",
      ", ----- ,\n",
      "\" ----- \"\n",
      "replied ----- reply\n",
      "Alex ----- Alex\n",
      ", ----- ,\n",
      "grinning ----- grin\n",
      "at ----- at\n",
      "his ----- his\n",
      "older ----- old\n",
      "brother ----- brother\n",
      ". ----- .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token,\"-----\",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c03b56aa-32a8-4aed-9247-a74ecf4c5f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ae23e8e-95c8-48b4-919c-62f1eb105f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "\n",
    "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"bruh\"}] ],{\"LEMMA\":\"brother\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bb8a8fb-654e-4843-a9fc-2f7caf7e5e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" ----- \"\n",
      "Bro ----- brother\n",
      ", ----- ,\n",
      "did ----- do\n",
      "you ----- you\n",
      "catch ----- catch\n",
      "the ----- the\n",
      "game ----- game\n",
      "last ----- last\n",
      "night ----- night\n",
      "? ----- ?\n",
      "\" ----- \"\n",
      "asked ----- ask\n",
      "Tom ----- Tom\n",
      ", ----- ,\n",
      "turning ----- turn\n",
      "to ----- to\n",
      "his ----- his\n",
      "younger ----- young\n",
      "sibling ----- sibling\n",
      ". ----- .\n",
      "\" ----- \"\n",
      "Yeah ----- yeah\n",
      ", ----- ,\n",
      "bruh ----- brother\n",
      ", ----- ,\n",
      "it ----- it\n",
      "was ----- be\n",
      "intense ----- intense\n",
      ", ----- ,\n",
      "\" ----- \"\n",
      "replied ----- reply\n",
      "Alex ----- Alex\n",
      ", ----- ,\n",
      "grinning ----- grin\n",
      "at ----- at\n",
      "his ----- his\n",
      "older ----- old\n",
      "brother ----- brother\n",
      ". ----- .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('''\"Bro, did you catch the game last night?\" asked Tom, turning to his younger sibling. \"Yeah, bruh, it was intense,\" replied Alex, grinning at his older brother.''')\n",
    "for token in doc:\n",
    "    print(token,\"-----\",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5bd44-3e7c-4eb7-ae4c-ec2c553994bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
